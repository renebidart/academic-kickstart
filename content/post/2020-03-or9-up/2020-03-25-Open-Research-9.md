---
author: Rene Bidart
date: "2020-03-30T00:00:00Z"
title: 'Keeping up with ML Research'
---

## How to keep up with deep learning research?

When I started my PhD I was totally overwhelmed at the amount of deep learning research being produced. Keeping up with research is important in any field, but it's so much more difficult in a fast moving field like machine learning. 

The fastest approach is to always read summaries (blogs, twitter threads, or newsletters) of papers before digging into them, because papers are slow to read. I made it a point that if something was worth looking at for more than 30 seconds, I'd write a quick summary of it to make sure I was understanding the main points.  My approach used to be to spend one day per week reviewing this (less now), because many newsletters come out every week, and it's easy to sort other sources like reddit by top weekly. 

## Resources

[Arxiv Sanity](http://www.arxiv-sanity.com/top?timefilter=week&vfilter=all) and [Papers with code](https://paperswithcode.com/) are probably the best way to see what real researchers are interested in.

[Reddit machine learning](https://www.reddit.com/r/MachineLearning/top/?t=week) is good, lots of smart people but high percentage of idiots and beginners, so lots of basic/clickbait stuff gets highly upvoted.

These are the best newsletters:

1. https://jack-clark.net/
2. https://www.deeplearning.ai/thebatch/
3. https://rohinshah.com/alignment-newsletter/ (good but very focused on AI safety)
4. https://chinai.substack.com/ (China specific, but useful because so much research and implementation happens there)

As far as legit research these are the best organizations to look at. They're good at hyping their research, so checking this could be redundant:

1. https://openai.com/blog/
2. https://deepmind.com/blog
3. https://ai.googleblog.com/

These rarely publish but are higher quality:

1. https://distill.pub/ (really good, but will take some time because you actually learn things reading it)
2. https://thegradient.pub/ (good quality blog)

There's a ton of good people on twitter, I made an account specifically as a news source, but most people recommend you actually engage with people. I made a [list](https://twitter.com/i/lists/1217249059016204288) of some good ones:

## How much time to spend on this?

This is the classic exploration-exploitation problem in reinforcement learning, and there's no right or wrong way to do it. Spending more time keeping up with random results in related fields to your core work lets you make better connections between fields, and can give you inspiration, but can easily eat up too much time. Once you've setted on a topic the key is learning to filter the research relevant to your subfield.

It's important to remember learning the basics is more important that furiously reading all the most recent research. Most research is quickly forgotten, and 5 years later the whole field will be condensed into a one semester course for undergrads. As long as you have a general idea of the field and anything relevant to your specific subfield you'll probably be fine, and extra time is better spent producing something.



